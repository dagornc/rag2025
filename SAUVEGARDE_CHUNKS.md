# Sauvegarde des Chunks

## Vue d'ensemble

Le pipeline sauvegarde automatiquement les chunks cr√©√©s √† partir des documents extraits au format JSON.

**Avantages** :
- ‚úÖ Conservation des chunks pour analyse et d√©bogage
- ‚úÖ M√©tadonn√©es compl√®tes (index, fichier source, etc.)
- ‚úÖ Format JSON facilement exploitable
- ‚úÖ Organisation par document source ou fichier unique

## Configuration

Configuration dans `config/03_chunking.yaml` :

```yaml
output:
  save_chunks: true                      # Activer la sauvegarde des chunks
  chunks_dir: "./data/output/chunks"     # R√©pertoire pour fichiers JSON
  format: "json"                         # Format de sauvegarde
  group_by_document: true                # Un fichier JSON par document source
  add_timestamp: true                    # Ajouter timestamp au nom du fichier
  pretty_print: true                     # Formater le JSON (indentation)
  include_metadata: true                 # Inclure toutes les m√©tadonn√©es
```

## Structure des fichiers JSON

### Mode group√© par document (`group_by_document: true`)

**Structure** :
```
data/output/chunks/
‚îú‚îÄ‚îÄ rapport_20251031_120651_chunks.json       # Chunks du rapport.pdf
‚îú‚îÄ‚îÄ guide_20251031_120652_chunks.json         # Chunks du guide.pdf
‚îî‚îÄ‚îÄ audit_20251031_120653_chunks.json         # Chunks de audit.docx
```

**Contenu d'un fichier** :
```json
[
  {
    "text": "Rapport d'Audit de S√©curit√©\n\nContexte\n\nCe rapport pr√©sente les r√©sultats de l'audit de s√©curit√© r√©alis√©...",
    "source_file": "/Users/.../data/input/docs/rapport.pdf",
    "chunk_index": 0,
    "total_chunks": 166
  },
  {
    "text": "M√©thodologie\n\nL'audit a √©t√© r√©alis√© selon la norme ISO 27001 en suivant...",
    "source_file": "/Users/.../data/input/docs/rapport.pdf",
    "chunk_index": 1,
    "total_chunks": 166
  },
  {
    "text": "R√©sultats\n\nL'audit a r√©v√©l√© plusieurs vuln√©rabilit√©s critiques...",
    "source_file": "/Users/.../data/input/docs/rapport.pdf",
    "chunk_index": 2,
    "total_chunks": 166
  }
  // ... 163 autres chunks
]
```

### Mode unique (`group_by_document: false`)

**Structure** :
```
data/output/chunks/
‚îî‚îÄ‚îÄ chunks_20251031_120651.json  # Tous les chunks de tous les documents
```

**Contenu** :
```json
[
  {
    "text": "Chunk du rapport.pdf...",
    "source_file": "/path/to/rapport.pdf",
    "chunk_index": 0,
    "total_chunks": 166
  },
  {
    "text": "Chunk du guide.pdf...",
    "source_file": "/path/to/guide.pdf",
    "chunk_index": 0,
    "total_chunks": 85
  }
  // ... tous les chunks de tous les documents
]
```

## M√©tadonn√©es des chunks

Chaque chunk contient :

| Champ | Type | Description |
|---|---|---|
| `text` | string | Texte du chunk |
| `source_file` | string | Chemin absolu du fichier source |
| `chunk_index` | int | Index du chunk dans le document (commence √† 0) |
| `total_chunks` | int | Nombre total de chunks pour ce document |

## Cas d'usage

### 1. Analyser les chunks d'un document

```bash
# Lire les chunks d'un document sp√©cifique
cat data/output/chunks/rapport_*_chunks.json | jq '.'

# Compter le nombre de chunks
cat data/output/chunks/rapport_*_chunks.json | jq 'length'

# Extraire le texte du premier chunk
cat data/output/chunks/rapport_*_chunks.json | jq '.[0].text'
```

### 2. Rechercher un mot-cl√© dans les chunks

```bash
# Trouver tous les chunks contenant "RGPD"
find data/output/chunks -name "*.json" -exec jq '.[] | select(.text | contains("RGPD"))' {} \;

# Compter le nombre de chunks contenant "s√©curit√©"
find data/output/chunks -name "*.json" -exec jq '[.[] | select(.text | contains("s√©curit√©"))] | length' {} \;
```

### 3. Statistiques sur les chunks

```bash
# Taille moyenne des chunks par document
for file in data/output/chunks/*_chunks.json; do
    echo "$(basename $file):"
    jq '[.[].text | length] | add / length' "$file"
done

# Distribution des tailles de chunks
jq '[.[].text | length] | group_by(. / 100 | floor * 100) | map({size: .[0], count: length})' \
   data/output/chunks/rapport_*_chunks.json
```

### 4. Exporter en texte brut

```python
import json
from pathlib import Path

# Lire les chunks d'un document
chunks_file = Path("data/output/chunks/rapport_20251031_120651_chunks.json")
with open(chunks_file, "r", encoding="utf-8") as f:
    chunks = json.load(f)

# Sauvegarder chaque chunk dans un fichier texte s√©par√©
output_dir = Path("data/output/chunks_txt")
output_dir.mkdir(exist_ok=True)

for chunk in chunks:
    chunk_idx = chunk["chunk_index"]
    filename = f"chunk_{chunk_idx:03d}.txt"

    with open(output_dir / filename, "w", encoding="utf-8") as f:
        f.write(chunk["text"])

print(f"‚úÖ {len(chunks)} chunks export√©s vers {output_dir}")
```

### 5. Reconstituer le document complet

```python
import json
from pathlib import Path

# Lire les chunks
chunks_file = Path("data/output/chunks/rapport_20251031_120651_chunks.json")
with open(chunks_file, "r", encoding="utf-8") as f:
    chunks = json.load(f)

# Trier par index (normalement d√©j√† tri√©)
chunks_sorted = sorted(chunks, key=lambda x: x["chunk_index"])

# Reconstituer le texte complet (attention au overlap)
# Note: cela cr√©e des duplications dues au chunk_overlap
full_text = "\n\n".join(chunk["text"] for chunk in chunks_sorted)

# Sauvegarder
output_file = Path("data/output/rapport_reconstruit.txt")
output_file.write_text(full_text, encoding="utf-8")

print(f"‚úÖ Document reconstitu√©: {output_file}")
print(f"   {len(full_text)} caract√®res")
```

## Logs

**Sauvegarde r√©ussie (mode group√©)** :
```
INFO: Chunking: 166 chunks cr√©√©s depuis 1 documents
INFO: üíæ Chunks sauvegard√©s: rapport_20251031_120651_chunks.json (166 chunks)
```

**Sauvegarde r√©ussie (mode unique)** :
```
INFO: Chunking: 251 chunks cr√©√©s depuis 3 documents
INFO: üíæ Chunks sauvegard√©s: chunks_20251031_120651.json (251 chunks)
```

**Erreur de sauvegarde** :
```
ERROR: Erreur sauvegarde chunks JSON: Permission denied
```
Note: En cas d'erreur, le pipeline continue (la sauvegarde n'est pas bloquante).

## Options de configuration

### D√©sactiver la sauvegarde

```yaml
output:
  save_chunks: false  # Aucun fichier JSON cr√©√©
```

### Sauvegarde unique pour tous les documents

```yaml
output:
  save_chunks: true
  group_by_document: false  # Un seul fichier pour tous les chunks
  add_timestamp: true
```

### Sauvegarde compacte (sans indentation)

```yaml
output:
  save_chunks: true
  pretty_print: false  # JSON compact (√©conomise de l'espace)
```

### Sauvegarde avec noms de fichiers sans timestamp

```yaml
output:
  save_chunks: true
  add_timestamp: false  # Noms de fichiers sans timestamp
  # Attention: risque d'√©crasement si m√™me document retrait√©
```

## Strat√©gies de chunking

Le d√©coupage en chunks affecte la structure des fichiers JSON :

### Strat√©gie "recursive" (recommand√©e)

```yaml
strategy: "recursive"
recursive:
  chunk_size: 1000      # Chunks de ~1000 caract√®res
  chunk_overlap: 200    # Overlap de 200 caract√®res
```

**R√©sultat** :
- Chunks de taille variable (~800-1200 caract√®res)
- D√©coupage intelligent sur paragraphes/lignes
- Chevauchement pour pr√©server le contexte

**Exemple** :
```
Document de 132808 chars ‚Üí 166 chunks
Taille moyenne: 800 chars/chunk
Taille min: 500 chars
Taille max: 1200 chars
```

### Strat√©gie "fixed"

```yaml
strategy: "fixed"
fixed:
  chunk_size: 1000
  overlap: 200
```

**R√©sultat** :
- Chunks de taille exacte (1000 caract√®res)
- D√©coupage sur position fixe (peut couper au milieu d'un mot)
- Plus rapide mais moins intelligent

## Performance

**Impact sur les performances** :
- Sauvegarde rapide (~5-10ms par fichier JSON)
- Espace disque : ~5-10% de la taille des documents originaux
- Mode group√© : plus de fichiers mais plus facile √† naviguer
- Mode unique : un seul fichier mais plus gros

**Exemple de tailles** :
```
Document PDF : 2 MB
‚Üí Texte extrait JSON : 200 KB
‚Üí Chunks JSON : 220 KB (166 chunks)
```

## Int√©gration avec les √©tapes suivantes

Les chunks JSON peuvent √™tre utilis√©s par :

**√âtape 4 (Enrichment)** : Enrichir les chunks avec m√©tadonn√©es
**√âtape 6 (Embedding)** : Cr√©er embeddings depuis les chunks JSON
**√âtape 8 (Vector Storage)** : Stocker les chunks dans la base vectorielle

## D√©sactivation temporaire

**Via configuration** :
```yaml
output:
  save_chunks: false
```

**Relancer le pipeline** :
```bash
./start.sh
```

## R√©sum√©

La sauvegarde des chunks permet de :

1. ‚úÖ **Conserver** les chunks pour analyse et d√©bogage
2. ‚úÖ **Tracer** la structure du d√©coupage
3. ‚úÖ **Explorer** facilement avec outils JSON (jq, Python)
4. ‚úÖ **Optimiser** le chunking en analysant les r√©sultats
5. ‚úÖ **Auditer** le traitement avec m√©tadonn√©es compl√®tes

**Configuration recommand√©e** :
```yaml
output:
  save_chunks: true
  group_by_document: true    # Un fichier par document
  add_timestamp: true        # √âvite les √©crasements
  pretty_print: true         # Lisible pour d√©bogage
```

**Commandes utiles** :
```bash
# V√©rifier les chunks cr√©√©s
ls -lh data/output/chunks/

# Lire les chunks d'un document
jq '.' data/output/chunks/rapport_*_chunks.json | less

# Compter les chunks par document
find data/output/chunks -name "*_chunks.json" -exec sh -c 'echo "$1: $(jq length "$1") chunks"' _ {} \;
```
