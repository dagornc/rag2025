# Guide des Profils de Fallback pour l'Extraction de Documents

## Vue d'ensemble

Le syst√®me de fallback du preprocessing (√©tape 2) supporte **5 profils pr√©d√©finis** qui optimisent automatiquement la cha√Æne d'extraction selon vos besoins :

- üöÄ **speed** : Rapidit√© maximale
- üíæ **memory** : Utilisation m√©moire minimale
- ‚öñÔ∏è **compromise** : √âquilibre qualit√©/performance
- üíé **quality** : Qualit√© maximale
- üéØ **custom** : Configuration manuelle

---

## Configuration

Dans `config/02_preprocessing.yaml` :

```yaml
fallback:
  enabled: true
  profile: "compromise"  # Choisir : speed | memory | compromise | quality | custom
```

---

## Profils D√©taill√©s

### 1Ô∏è‚É£ Profil `speed` - Rapidit√© Maximale

**Cas d'usage :**
- Traitement de gros volumes de documents
- PDF textuels simples (rapports, contrats, articles)
- Besoin de latence minimale
- Documents g√©n√©r√©s num√©riquement (pas scann√©s)

**Extracteurs :**
```
PyPDF2 uniquement
```

**Caract√©ristiques :**
| M√©trique | Valeur |
|----------|--------|
| RAM | ~50 MB |
| Vitesse | ‚ö°‚ö°‚ö°‚ö°‚ö° (5/5) |
| Qualit√© | ‚≠ê‚≠ê (2/5) |
| Temps moyen | 0.1-0.5s / doc |

**Limites :**
- ‚ùå PDF scann√©s (images)
- ‚ùå Mises en page complexes
- ‚ùå Tableaux structur√©s
- ‚ùå OCR

**Exemple de r√©sultat :**
```python
{
    "extraction_method": "pypdf2",
    "confidence_score": 0.4,
    "extraction_time_seconds": 0.12
}
```

---

### 2Ô∏è‚É£ Profil `memory` - Utilisation M√©moire Minimale

**Cas d'usage :**
- Serveurs avec RAM limit√©e (< 2 GB)
- Environnements cloud avec quotas m√©moire
- Containers Docker l√©gers
- Documents vari√©s (textuels + scann√©s occasionnels)

**Extracteurs :**
```
1. PyPDF2 (rapide, 50 MB)
   ‚Üì (si √©chec)
2. Docling (OCR, 200 MB) - sans ML lourd
```

**Caract√©ristiques :**
| M√©trique | Valeur |
|----------|--------|
| RAM | ~200 MB |
| Vitesse | ‚ö°‚ö°‚ö°‚ö° (4/5) |
| Qualit√© | ‚≠ê‚≠ê‚≠ê (3/5) |
| Temps moyen | 0.5-2s / doc |

**Avantages :**
- ‚úÖ OCR pour PDF scann√©s
- ‚úÖ Analyse de layout basique
- ‚úÖ √âvite Marker (mod√®les ML lourds)
- ‚úÖ Bonne compatibilit√©

**Configuration appliqu√©e :**
```yaml
extractors:
  - name: pypdf2
    config:
      min_text_length: 100
      min_confidence: 0.3

  - name: docling
    config:
      ocr_enabled: true
      extract_tables: false  # D√©sactiv√© pour √©conomiser RAM
      min_confidence: 0.4
```

---

### 3Ô∏è‚É£ Profil `compromise` - √âquilibre Optimal (D√âFAUT)

**Cas d'usage :**
- Usage g√©n√©ral production
- Documents professionnels vari√©s
- Budget m√©moire raisonnable (< 1 GB)
- Besoin de qualit√© correcte sans latence excessive

**Extracteurs :**
```
1. PyPDF2 (rapide, textuels simples)
   ‚Üì (si √©chec)
2. Docling (OCR + layout + tableaux)
```

**Caract√©ristiques :**
| M√©trique | Valeur |
|----------|--------|
| RAM | ~300 MB |
| Vitesse | ‚ö°‚ö°‚ö° (3/5) |
| Qualit√© | ‚≠ê‚≠ê‚≠ê‚≠ê (4/5) |
| Temps moyen | 1-3s / doc |

**Avantages :**
- ‚úÖ OCR pour PDF scann√©s
- ‚úÖ Extraction de tableaux structur√©s
- ‚úÖ Analyse de layout avanc√©e
- ‚úÖ Bon compromis vitesse/qualit√©
- ‚úÖ Recommand√© pour 80% des cas

**Configuration appliqu√©e :**
```yaml
extractors:
  - name: pypdf2
    config:
      min_text_length: 100
      min_confidence: 0.3

  - name: docling
    config:
      ocr_enabled: true
      extract_tables: true  # Tableaux activ√©s
      min_confidence: 0.5
```

**Exemple de r√©sultat :**
```python
{
    "extraction_method": "docling",
    "confidence_score": 0.85,
    "metadata": {
        "num_pages": 12,
        "tables_count": 3
    },
    "extraction_time_seconds": 2.3
}
```

---

### 4Ô∏è‚É£ Profil `quality` - Qualit√© Maximale

**Cas d'usage :**
- Documents critiques (contrats, dossiers m√©dicaux)
- PDF complexes (scientifiques, techniques)
- Besoin de pr√©cision maximale
- Extraction de formules math√©matiques
- Dernier recours pour documents illisibles

**Extracteurs :**
```
1. Marker (ML, haute pr√©cision)
   ‚Üì (si √©chec)
2. Docling (OCR + layout)
   ‚Üì (si √©chec)
3. VLM (Vision AI - GPT-4V, Claude 3)
```

**Caract√©ristiques :**
| M√©trique | Valeur |
|----------|--------|
| RAM | ~2 GB (CPU) / ~6 GB (GPU) |
| Vitesse | ‚ö°‚ö° (2/5) |
| Qualit√© | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5) |
| Temps moyen | 5-20s / doc (CPU) |
| Co√ªt | $0.01-0.05 / doc (VLM) |

**Avantages :**
- ‚úÖ Mod√®les ML de pointe (Marker)
- ‚úÖ Pr√©serve structure complexe
- ‚úÖ Gestion des √©quations/formules
- ‚úÖ Fallback VLM pour documents impossibles
- ‚úÖ Qualit√© proche de l'humain

**Limites :**
- ‚ö†Ô∏è Lent (5-20s / document)
- ‚ö†Ô∏è N√©cessite beaucoup de RAM
- ‚ö†Ô∏è VLM co√ªte de l'argent (API)
- ‚ö†Ô∏è GPU recommand√© pour Marker

**Configuration appliqu√©e :**
```yaml
extractors:
  - name: marker
    config:
      use_gpu: false  # Passer √† true si GPU disponible
      min_confidence: 0.6

  - name: docling
    config:
      ocr_enabled: true
      extract_tables: true
      min_confidence: 0.5

  - name: vlm
    config:
      provider: "openai"  # Ou : anthropic, ollama, etc.
      model: "gpt-4-vision-preview"
      max_pages: 10  # Limite pour √©viter co√ªts excessifs
      min_confidence: 0.4
```

**Exemple de r√©sultat :**
```python
{
    "extraction_method": "marker",
    "confidence_score": 0.95,
    "metadata": {
        "num_pages": 25,
        "images_extracted": 8,
        "tables_count": 5
    },
    "extraction_time_seconds": 12.4
}
```

---

### 5Ô∏è‚É£ Profil `custom` - Configuration Manuelle

**Cas d'usage :**
- Besoins tr√®s sp√©cifiques
- Fine-tuning de la cha√Æne de fallback
- Tests et exp√©rimentations
- Optimisation pour un type de document pr√©cis

**Configuration :**

Lorsque `profile: "custom"`, le syst√®me utilise directement la section `extractors` de votre config YAML.

**Exemple 1 : Seulement Docling (PDF scann√©s uniquement)**

```yaml
fallback:
  profile: "custom"
  extractors:
    - name: "docling"
      enabled: true
      config:
        ocr_enabled: true
        extract_tables: true
        min_confidence: 0.3
```

**Exemple 2 : Marker + VLM (qualit√© extr√™me, pas de PyPDF2)**

```yaml
fallback:
  profile: "custom"
  extractors:
    - name: "marker"
      enabled: true
      config:
        use_gpu: true
        max_pages: null

    - name: "vlm"
      enabled: true
      config:
        provider: "anthropic"
        model: "claude-3-opus-20240229"
        max_pages: 20
        temperature: 0.0
```

**Exemple 3 : Ordre invers√© (VLM en premier)**

```yaml
fallback:
  profile: "custom"
  extractors:
    # VLM en premier (pour documents sp√©ciaux)
    - name: "vlm"
      enabled: true
      config:
        provider: "ollama"
        model: "llava:13b"
        max_pages: 5

    # Fallback classique
    - name: "pypdf2"
      enabled: true
```

---

## Tableau Comparatif

| Profil | RAM | Vitesse | Qualit√© | Co√ªt | Cas d'usage principal |
|--------|-----|---------|---------|------|----------------------|
| **speed** | 50 MB | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê | Gratuit | Gros volumes, PDF simples |
| **memory** | 200 MB | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | Gratuit | Serveurs limit√©s |
| **compromise** | 300 MB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Gratuit | Usage g√©n√©ral (d√©faut) |
| **quality** | 2 GB | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | $0.01-0.05 / doc | Documents critiques |
| **custom** | Variable | Variable | Variable | Variable | Besoins sp√©cifiques |

---

## Arbre de D√©cision

```
Quel est votre besoin principal ?

‚îú‚îÄ Rapidit√© maximale ?
‚îÇ  ‚îî‚îÄ ‚Üí profile: "speed"
‚îÇ
‚îú‚îÄ RAM limit√©e (< 1 GB) ?
‚îÇ  ‚îî‚îÄ ‚Üí profile: "memory"
‚îÇ
‚îú‚îÄ Qualit√© critique ?
‚îÇ  ‚îú‚îÄ Oui + Budget OK pour VLM
‚îÇ  ‚îÇ  ‚îî‚îÄ ‚Üí profile: "quality"
‚îÇ  ‚îî‚îÄ Non
‚îÇ     ‚îî‚îÄ ‚Üí profile: "compromise"
‚îÇ
‚îî‚îÄ Besoin tr√®s sp√©cifique ?
   ‚îî‚îÄ ‚Üí profile: "custom"
```

---

## Configuration VLM pour le Profil `quality`

### Architecture Unifi√©e LLM/VLM

**IMPORTANT** : Les VLM (Vision Language Models) utilisent la **m√™me architecture** que les LLM.

Les providers VLM sont d√©finis dans `global.yaml > llm_providers` et chaque extracteur VLM sp√©cifie :
- `provider` : Nom du provider (doit exister dans global.yaml)
- `model` : Nom du mod√®le vision √† utiliser
- `temperature` : Param√®tre de g√©n√©ration

### Configuration dans `global.yaml`

Les providers suivants supportent les mod√®les **vision** :

```yaml
llm_providers:
  # OpenAI - GPT-4 Vision, GPT-4o (mod√®les vision haute qualit√©)
  openai:
    access_method: "openai_compatible"
    base_url: "https://api.openai.com/v1"
    api_key: "${OPENAI_API_KEY}"  # Variable d'environnement

  # Anthropic - Claude 3 avec capacit√© vision (Opus, Sonnet)
  anthropic:
    access_method: "openai_compatible"
    base_url: "https://api.anthropic.com/v1"
    api_key: "${ANTHROPIC_API_KEY}"

  # Ollama - LLaVA (mod√®les vision open-source, gratuit, local)
  ollama:
    access_method: "openai_compatible"
    base_url: "http://localhost:11434/v1"
    api_key: "ollama"  # Pas besoin de vraie cl√©
```

### Mod√®les VLM Disponibles par Provider

| Provider | Mod√®les Vision | Qualit√© | Co√ªt | Vitesse |
|----------|----------------|---------|------|---------|
| **openai** | `gpt-4-vision-preview`<br>`gpt-4o`<br>`gpt-4-turbo` | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | $0.01-0.03/page | Moyen |
| **anthropic** | `claude-3-opus-20240229`<br>`claude-3-sonnet-20240229` | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | $0.02-0.05/page | Moyen |
| **ollama** | `llava:13b`<br>`llava:7b`<br>`bakllava` | ‚≠ê‚≠ê‚≠ê | Gratuit | Lent (CPU) |

### Configuration dans Fallback Profile

Dans `config/02_preprocessing.yaml` (ou via profil predefined) :

```yaml
extractors:
  - name: "vlm"
    enabled: true
    config:
      provider: "openai"  # R√©f√©rence √† global.yaml > llm_providers
      model: "gpt-4-vision-preview"
      temperature: 0.0
      max_tokens_per_page: 2000
      max_pages: 10  # Limite pour √©viter co√ªts excessifs
```

**Recommandations** :
- OpenAI `gpt-4o` : Meilleur rapport qualit√©/prix/vitesse
- Anthropic `claude-3-opus` : Meilleure qualit√© absolue
- Ollama `llava:13b` : Gratuit pour tests/d√©veloppement

---

## M√©triques et Monitoring

Le syst√®me enregistre automatiquement des m√©triques pour chaque extraction :

```python
{
    "file_path": "contrat_2024.pdf",
    "extraction_method": "docling",  # Quel extracteur a r√©ussi
    "confidence_score": 0.85,
    "original_length": 45230,
    "cleaned_length": 42100,
    "metadata": {
        "extraction_time_seconds": 2.3,
        "num_pages": 12,
        "tables_count": 3
    }
}
```

**Analyser les performances :**

```python
from pathlib import Path
import json

# Charger les r√©sultats d'extraction
results = data["extracted_documents"]

# Statistiques par extracteur
from collections import Counter
methods = Counter(doc["extraction_method"] for doc in results)
print(f"M√©thodes utilis√©es : {methods}")
# ‚Üí {'pypdf2': 45, 'docling': 12, 'marker': 3}

# Temps moyen d'extraction
avg_time = sum(
    doc["metadata"]["extraction_time_seconds"]
    for doc in results
) / len(results)
print(f"Temps moyen : {avg_time:.2f}s")
```

---

## FAQ

### Q1 : Puis-je changer de profil dynamiquement ?

Oui, vous pouvez modifier `config/02_preprocessing.yaml` et relancer le pipeline. Aucun changement de code n√©cessaire.

### Q2 : Le profil `quality` n√©cessite-t-il toujours une API payante ?

Non. Si vous utilisez Ollama avec LLaVA en local, le VLM est gratuit. Mais la qualit√© sera inf√©rieure √† GPT-4V.

### Q3 : Que se passe-t-il si tous les extracteurs √©chouent ?

Le syst√®me l√®ve une `RuntimeError` avec le d√©tail de tous les √©checs. Vous pouvez activer `error_handling.skip_on_error: true` pour ignorer le document.

### Q4 : Comment optimiser le profil `quality` pour r√©duire les co√ªts VLM ?

Dans le profil quality, r√©duisez `max_pages` du VLM :

```yaml
extractors:
  - name: vlm
    config:
      max_pages: 5  # Traiter maximum 5 pages avec VLM
```

### Q5 : Peut-on cr√©er ses propres profils pr√©d√©finis ?

Oui ! Modifiez `rag_framework/extractors/fallback_manager.py` :

```python
PROFILES: ClassVar[dict[str, list[dict[str, Any]]]] = {
    # ... profils existants ...

    # Votre profil custom
    "mon_profil": [
        {
            "name": "docling",
            "enabled": True,
            "config": {"ocr_enabled": True}
        }
    ]
}
```

Puis utilisez `profile: "mon_profil"` dans votre config.

---

## Bonnes Pratiques

1. **Commencez par `compromise`** : C'est le meilleur √©quilibre pour 80% des cas
2. **Utilisez `speed` pour les prototypes** : Tests rapides pendant le d√©veloppement
3. **Passez √† `quality` pour la production critique** : Documents importants seulement
4. **Activez `memory` sur les petits serveurs** : √âvite les crashes OOM
5. **Loggez les m√©triques** : Analysez quel extracteur est le plus utilis√©
6. **Testez avec vos documents r√©els** : Chaque corpus est diff√©rent

---

## Exemples Complets

### Exemple 1 : Startup avec budget limit√©

```yaml
fallback:
  profile: "memory"  # RAM limit√©e sur serveur cloud
```

### Exemple 2 : Entreprise avec documents critiques

```yaml
fallback:
  profile: "quality"  # Qualit√© maximale, budget OK
```

### Exemple 3 : Plateforme grand public

```yaml
fallback:
  profile: "compromise"  # Bon compromis pour tous
```

### Exemple 4 : Pipeline de recherche

```yaml
fallback:
  profile: "custom"
  extractors:
    - name: "marker"  # Qualit√© scientifique
      enabled: true
      config:
        use_gpu: true
        max_pages: null
```

---

## Conclusion

Le syst√®me de profils de fallback permet d'**adapter automatiquement** l'extraction √† votre contexte :

- üöÄ **Speed** : D√©marrage rapide, tests
- üíæ **Memory** : Serveurs limit√©s
- ‚öñÔ∏è **Compromise** : Production g√©n√©rale (recommand√©)
- üíé **Quality** : Documents critiques
- üéØ **Custom** : Besoins sp√©cifiques

**Recommandation :** Commencez avec `compromise`, mesurez les performances, puis ajustez si n√©cessaire.
