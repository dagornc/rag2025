"""√âtape 5 : Audit logging et tra√ßabilit√©."""

import json
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Optional

from rag_framework.config import get_llm_client, load_config
from rag_framework.exceptions import StepExecutionError, ValidationError
from rag_framework.steps.base_step import BaseStep
from rag_framework.types import StepData
from rag_framework.utils.logger import get_logger

logger = get_logger(__name__)


class AuditStep(BaseStep):
    """√âtape 5 : Audit logging et tra√ßabilit√©."""

    def __init__(self, config: dict[str, Any]) -> None:
        """Initialise l'√©tape d'audit.

        Parameters
        ----------
        config : dict[str, Any]
            Configuration de l'√©tape.
        """
        super().__init__(config)

        # Chargement de la config globale pour acc√®s aux LLM providers
        self.global_config = load_config()

        # Initialisation du client LLM si activ√© dans la config
        self.llm_client: Optional[Any] = None
        llm_config = self.config.get("llm", {})

        if llm_config.get("enabled", False):
            try:
                # R√©cup√©ration des param√®tres fonctionnels depuis la config de l'√©tape
                provider = llm_config.get("provider")
                model = llm_config.get("model")
                temperature = llm_config.get("temperature", 0.3)

                # Validation des param√®tres obligatoires
                if not provider or not model:
                    logger.warning(
                        "LLM activ√© mais configuration incompl√®te "
                        "(provider/model manquant). "
                        "R√©sum√©s d'audit d√©sactiv√©s."
                    )
                else:
                    # Cr√©ation du client LLM via la fonction helper
                    self.llm_client = get_llm_client(
                        provider_name=provider,
                        model=model,
                        temperature=temperature,
                        global_config=self.global_config,
                    )
                    logger.info(
                        f"LLM activ√© pour r√©sum√©s d'audit: {provider}/{model} "
                        f"(temperature={temperature})"
                    )

            except Exception as e:
                logger.warning(
                    f"Erreur lors de l'initialisation du client LLM: {e}. "
                    "R√©sum√©s d'audit d√©sactiv√©s."
                )
                self.llm_client = None

    def validate_config(self) -> None:
        """Valide la configuration de l'√©tape."""
        if "audit_logging" not in self.config:
            raise ValidationError(
                "Cl√© 'audit_logging' manquante dans la configuration",
                details={"step": "AuditStep"},
            )

    def execute(self, data: StepData) -> StepData:
        """Enregistre un audit trail complet de l'op√©ration.

        Args:
            data: Donn√©es contenant les r√©sultats des √©tapes pr√©c√©dentes.

        Returns:
            Donn√©es avec 'audit_record' ajout√©.

        Raises:
            StepExecutionError: En cas d'erreur durant l'audit.
        """
        try:
            audit_config = self.config.get("audit_logging", {})

            # Cr√©ation de l'enregistrement d'audit
            audit_record = {
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "operation": "rag_pipeline_execution",
                "documents_processed": len(data.get("extracted_documents", [])),
                "chunks_created": len(data.get("enriched_chunks", [])),
                "metadata": {
                    "monitoring_config": data.get("monitoring_config", {}),
                    "files_processed": [
                        doc["file_path"] for doc in data.get("extracted_documents", [])
                    ],
                },
            }

            # Enregistrement dans le fichier d'audit
            if audit_config.get("log_all_operations", True):
                self._write_audit_log(audit_record, audit_config)

            # G√©n√©ration d'un r√©sum√© narratif avec LLM si activ√©
            if self.llm_client is not None:
                try:
                    audit_summary = self._generate_audit_summary(audit_record)
                    audit_record["llm_summary"] = audit_summary
                    logger.info("R√©sum√© d'audit g√©n√©r√© avec LLM")

                    # Sauvegarde du r√©sum√© dans un fichier s√©par√© si configur√©
                    output_config = self.config.get("output", {})
                    if output_config.get("save_summaries", False):
                        self._save_audit_summary(audit_record, output_config)

                except Exception as e:
                    logger.warning(
                        f"Erreur lors de la g√©n√©ration du r√©sum√© d'audit: {e}"
                    )
                    audit_record["llm_summary"] = None

            data["audit_record"] = audit_record
            logger.info("Audit: Enregistrement cr√©√© avec succ√®s")

            return data

        except Exception as e:
            raise StepExecutionError(
                step_name="AuditStep",
                message=f"Erreur lors de l'audit: {e!s}",
                details={"error": str(e)},
            ) from e

    def _write_audit_log(
        self,
        audit_record: dict[str, Any],
        audit_config: dict[str, Any],
    ) -> None:
        """√âcrit l'enregistrement d'audit dans le fichier de log.

        Args:
            audit_record: Enregistrement d'audit.
            audit_config: Configuration de l'audit.
        """
        log_file = audit_config.get("log_file", "logs/audit_trail.jsonl")
        log_path = Path(log_file)

        # Cr√©er le r√©pertoire si n√©cessaire
        log_path.parent.mkdir(parents=True, exist_ok=True)

        # √âcriture en mode append (JSONL)
        with open(log_path, "a", encoding="utf-8") as f:
            f.write(json.dumps(audit_record, ensure_ascii=False) + "\n")

    def _generate_audit_summary(self, audit_record: dict[str, Any]) -> str:
        """G√©n√®re un r√©sum√© narratif de l'audit avec LLM.

        Parameters
        ----------
        audit_record : dict[str, Any]
            Enregistrement d'audit structur√©.

        Returns:
        -------
        str
            R√©sum√© narratif lisible par un humain.
        """
        # Construction de la liste des fichiers trait√©s
        files_list = "\n".join(
            f"- {file}" for file in audit_record["metadata"].get("files_processed", [])
        )

        # R√©cup√©ration du prompt depuis la configuration
        # Permet de personnaliser le prompt sans modifier le code
        prompt_template = self.config.get("llm", {}).get("prompts", {}).get(
            "audit_summary",
            # Prompt par d√©faut si non configur√© (fallback)
            """G√©n√®re un r√©sum√© narratif professionnel de cette op√©ration d'audit.

Timestamp: {timestamp}
Op√©ration: {operation}
Documents trait√©s: {documents_processed}
Chunks cr√©√©s: {chunks_created}

Fichiers trait√©s:
{files_list}

R√©dige un r√©sum√© concis (2-3 phrases) adapt√© pour un rapport de conformit√©.
Le r√©sum√© doit √™tre factuel, professionnel et sans interpr√©tation subjective.""",
        )

        # Substitution des placeholders avec les donn√©es de l'audit
        prompt = prompt_template.format(
            timestamp=audit_record["timestamp"],
            operation=audit_record["operation"],
            documents_processed=audit_record["documents_processed"],
            chunks_created=audit_record["chunks_created"],
            files_list=files_list,
        )

        # Appel au LLM pour g√©n√©ration du r√©sum√©
        assert self.llm_client is not None
        response = self.llm_client.chat.completions.create(
            model=self.llm_client._model,
            messages=[{"role": "user", "content": prompt}],
            temperature=self.llm_client._temperature,
            max_tokens=self.config.get("llm", {}).get("max_tokens", 1000),
        )

        # Extraction du r√©sum√© g√©n√©r√©
        content = response.choices[0].message.content
        if content is None:
            return "Erreur: le LLM a retourn√© un r√©sum√© vide."

        summary: str = content.strip()

        return summary

    def _save_audit_summary(
        self,
        audit_record: dict[str, Any],
        output_config: dict[str, Any],
    ) -> None:
        """Sauvegarde le r√©sum√© d'audit dans un fichier s√©par√©.

        Parameters
        ----------
        audit_record : dict[str, Any]
            Enregistrement d'audit complet avec r√©sum√© LLM.
        output_config : dict[str, Any]
            Configuration de sauvegarde des r√©sum√©s.

        Examples
        --------
        >>> step = AuditStep(config)
        >>> audit_record = {"timestamp": "...", "llm_summary": "...", ...}
        >>> output_config = {"save_summaries": True, "summaries_dir": "./data/output/audit_summaries"}
        >>> step._save_audit_summary(audit_record, output_config)
        """
        try:
            # R√©pertoire de destination
            summaries_dir = Path(
                output_config.get("summaries_dir", "./data/output/audit_summaries")
            )
            summaries_dir.mkdir(parents=True, exist_ok=True)

            # Format de sauvegarde
            format_type = output_config.get("format", "json")

            # G√©n√©ration du nom de fichier
            timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename_template = output_config.get(
                "filename_template", "audit_summary_{timestamp}.{format}"
            )
            filename = filename_template.format(
                timestamp=timestamp_str, format=format_type
            )
            file_path = summaries_dir / filename

            # Pr√©paration du contenu √† sauvegarder
            if format_type == "json":
                self._save_json_summary(audit_record, file_path, output_config)
            elif format_type == "txt":
                self._save_txt_summary(audit_record, file_path, output_config)
            elif format_type == "markdown":
                self._save_markdown_summary(audit_record, file_path, output_config)
            else:
                logger.warning(
                    f"Format de sauvegarde inconnu: {format_type}, "
                    f"utilisation de JSON par d√©faut"
                )
                self._save_json_summary(audit_record, file_path, output_config)

            logger.info(f"üíæ R√©sum√© d'audit sauvegard√©: {filename}")
            logger.debug(f"  Chemin complet: {file_path}")

        except Exception as e:
            logger.error(
                f"Erreur sauvegarde r√©sum√© d'audit: {e}", exc_info=True
            )
            # Ne pas interrompre le pipeline en cas d'erreur de sauvegarde

    def _save_json_summary(
        self,
        audit_record: dict[str, Any],
        file_path: Path,
        output_config: dict[str, Any],
    ) -> None:
        """Sauvegarde le r√©sum√© d'audit au format JSON.

        Parameters
        ----------
        audit_record : dict[str, Any]
            Enregistrement d'audit complet.
        file_path : Path
            Chemin du fichier de destination.
        output_config : dict[str, Any]
            Configuration de sauvegarde.
        """
        # Construction du contenu JSON
        content = {}

        # M√©tadonn√©es de base
        if output_config.get("include_metadata", True):
            content["timestamp"] = audit_record.get("timestamp")
            content["operation"] = audit_record.get("operation")
            content["documents_processed"] = audit_record.get("documents_processed")
            content["chunks_created"] = audit_record.get("chunks_created")
            content["files_processed"] = audit_record.get("metadata", {}).get(
                "files_processed", []
            )

        # R√©sum√© LLM
        if output_config.get("include_llm_summary", True):
            content["llm_summary"] = audit_record.get("llm_summary")

        # Donn√©es brutes compl√®tes (optionnel)
        if output_config.get("include_raw_data", False):
            content["raw_audit_record"] = audit_record

        # √âcriture du fichier JSON
        indent = 2 if output_config.get("pretty_print", True) else None
        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(content, f, ensure_ascii=False, indent=indent)

    def _save_txt_summary(
        self,
        audit_record: dict[str, Any],
        file_path: Path,
        output_config: dict[str, Any],
    ) -> None:
        """Sauvegarde le r√©sum√© d'audit au format texte brut.

        Parameters
        ----------
        audit_record : dict[str, Any]
            Enregistrement d'audit complet.
        file_path : Path
            Chemin du fichier de destination.
        output_config : dict[str, Any]
            Configuration de sauvegarde.
        """
        # Modification de l'extension si n√©cessaire
        file_path = file_path.with_suffix(".txt")

        # Construction du contenu texte
        lines = []

        # En-t√™te
        lines.append("=" * 70)
        lines.append("R√âSUM√â D'AUDIT")
        lines.append("=" * 70)
        lines.append("")

        # M√©tadonn√©es
        if output_config.get("include_metadata", True):
            lines.append(f"Date: {audit_record.get('timestamp')}")
            lines.append(f"Op√©ration: {audit_record.get('operation')}")
            lines.append(
                f"Documents trait√©s: {audit_record.get('documents_processed')}"
            )
            lines.append(f"Chunks cr√©√©s: {audit_record.get('chunks_created')}")
            lines.append("")

            # Liste des fichiers
            files = audit_record.get("metadata", {}).get("files_processed", [])
            if files:
                lines.append("Fichiers trait√©s:")
                for file in files:
                    lines.append(f"  - {file}")
                lines.append("")

        # R√©sum√© LLM
        if output_config.get("include_llm_summary", True):
            lines.append("R√©sum√©:")
            lines.append("-" * 70)
            lines.append(audit_record.get("llm_summary", "N/A"))
            lines.append("")

        lines.append("=" * 70)

        # √âcriture du fichier texte
        with open(file_path, "w", encoding="utf-8") as f:
            f.write("\n".join(lines))

    def _save_markdown_summary(
        self,
        audit_record: dict[str, Any],
        file_path: Path,
        output_config: dict[str, Any],
    ) -> None:
        """Sauvegarde le r√©sum√© d'audit au format Markdown.

        Parameters
        ----------
        audit_record : dict[str, Any]
            Enregistrement d'audit complet.
        file_path : Path
            Chemin du fichier de destination.
        output_config : dict[str, Any]
            Configuration de sauvegarde.
        """
        # Modification de l'extension si n√©cessaire
        file_path = file_path.with_suffix(".md")

        # Construction du contenu Markdown
        lines = []

        # Titre
        lines.append("# R√©sum√© d'Audit")
        lines.append("")

        # M√©tadonn√©es
        if output_config.get("include_metadata", True):
            lines.append("## M√©tadonn√©es")
            lines.append("")
            lines.append(f"- **Date**: {audit_record.get('timestamp')}")
            lines.append(f"- **Op√©ration**: `{audit_record.get('operation')}`")
            lines.append(
                f"- **Documents trait√©s**: {audit_record.get('documents_processed')}"
            )
            lines.append(
                f"- **Chunks cr√©√©s**: {audit_record.get('chunks_created')}"
            )
            lines.append("")

            # Liste des fichiers
            files = audit_record.get("metadata", {}).get("files_processed", [])
            if files:
                lines.append("### Fichiers trait√©s")
                lines.append("")
                for file in files:
                    lines.append(f"- `{file}`")
                lines.append("")

        # R√©sum√© LLM
        if output_config.get("include_llm_summary", True):
            lines.append("## R√©sum√©")
            lines.append("")
            lines.append(audit_record.get("llm_summary", "*Aucun r√©sum√© disponible*"))
            lines.append("")

        # Footer
        lines.append("---")
        lines.append(
            f"*G√©n√©r√© automatiquement le {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*"
        )

        # √âcriture du fichier Markdown
        with open(file_path, "w", encoding="utf-8") as f:
            f.write("\n".join(lines))
