# =============================================================================
# VARIABLES D'ENVIRONNEMENT - Framework RAG Audit & Conformité
# =============================================================================
# Ce fichier est un template. Copiez-le vers .env et renseignez vos clés.
#
# Usage: cp .env.example .env && nano .env
#
# IMPORTANT: Ne jamais commiter .env dans git!
# =============================================================================

# -----------------------------------------------------------------------------
# PROVIDERS LLM/VLM CLOUD (Payants)
# -----------------------------------------------------------------------------

# OpenAI - GPT-4, embeddings, vision (https://platform.openai.com)
OPENAI_API_KEY=sk-...

# Anthropic - Claude 3 (https://console.anthropic.com)
# Mettre "unused" si vous n'utilisez pas Anthropic
ANTHROPIC_API_KEY=unused

# Mistral AI - Mistral, Mixtral (https://console.mistral.ai)
# Mettre "unused" si vous n'utilisez pas Mistral AI
MISTRAL_API_KEY=unused

# Hugging Face - Modèles communautaires (https://huggingface.co/settings/tokens)
# Mettre "unused" si vous n'utilisez pas Hugging Face
HUGGINGFACE_API_KEY=unused

# Generic API - Provider personnalisé compatible OpenAI
GENERIC_API_KEY=unused

# -----------------------------------------------------------------------------
# PROVIDERS LOCAUX (Gratuits)
# -----------------------------------------------------------------------------

# Ollama - LLM local (http://localhost:11434)
OLLAMA_HOST=http://localhost:11434

# LM Studio - LLM local (http://localhost:1234)
LM_STUDIO_HOST=http://localhost:1234

# vLLM - Serveur d'inférence local (http://localhost:8000)
VLLM_HOST=http://localhost:8000

# -----------------------------------------------------------------------------
# BASES DE DONNÉES VECTORIELLES
# -----------------------------------------------------------------------------

# Qdrant (optionnel si utilisation cloud)
# QDRANT_API_KEY=...
# QDRANT_URL=http://localhost:6333

# ChromaDB (aucune config nécessaire pour usage local)

# -----------------------------------------------------------------------------
# NOTES
# -----------------------------------------------------------------------------
# • Remplacez "unused" par vos vraies clés pour les providers que vous utilisez
# • Les providers locaux (Ollama, LM Studio, vLLM) ne nécessitent pas de clé API
# • Les URLs locales fonctionnent par défaut si les services sont démarrés
